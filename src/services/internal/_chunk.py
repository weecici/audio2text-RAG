import os
import asyncio
from google import genai
from google.genai import types
from typing import Literal
from functools import lru_cache
from src.core import config
from src.utils import logger

MODEL_ID = "gemini-flash-latest"


transcript_chunking_template = """
You are an expert at chunking transcripts of audio files for information retrieval systems. Follow these rules exactly and strictly to produce only the requested output — no explanations or extra text.

Parameters (replace placeholders):
- `max_token` (value: {max_token}): maximum tokens per chunk.
- `raw_document` (will be provided later): the raw document text.
- `lang` (value: {lang}): main language of the transcript. If set to 'auto', detect language automatically.

Behavior rules:
0. Steps to follow carefully: Syntax correction -> Chunking + Timestamps removal + Timestamp combination for output chunks -> Title generation -> Output formatting. (this rule is VERY IMPORTANT FOR YOU TO FOLLOW)
1. Correct only non-substantive syntax errors: punctuation, obvious typos, unmatched quotes, spacing and the most serious ones are mismatch/wrong/unrelated/nonsense words between speech and text generated by ASR system. Do NOT paraphrase, summarize, condense, or change facts or technical expressions.
2. Compute each chunk's start_time and end_time (in seconds) from the original timestamps and display them in the chunk title. Round to the nearest integer second (0.5 → round up). 
3. Each chunk must be coherent and contextually relevant. Aim for semantic unity (a chunk should cover a single topic/idea or tightly related set of sentences). However, don't break the transcript too short (< 3 sentences). (this rule is VERY IMPORTANT)
4. Maximum chunk size is `max_token` tokens. Use the specified tokenizer to count tokens.
5. Title each chunk with a short topic name (in the transcript's main language. It also mustn't contain some characters that are not allowed for filenames like '/') followed by start and end times as integers, using the exact format:
   <title> | <start_time> | <end_time>
6. Output formatting: produce consecutive chunks separated by a line of ten equals signs "==========" and each chunk must follow exactly this template:

<title N> | <start_time N> | <end_time N>
++++++++++
<chunk_text N>

==========
(repeat for all chunks)

7. Do not use any markdown styling (no bold, italic, underline). Convert math expression to LaTeX using inline ($...$) or display ($$...$$) (this rule is the MOST IMPORTANT)
8. Do not add any commentary, metadata, or notes outside the specified format.

Now process the transcript below using these rules:
{transcript}
"""

document_chunking_template = """
Parameters (replace placeholders):
- `max_token` (value: {max_token}): maximum tokens per chunk.
- `raw_document` (will be provided later): the raw document text.
- `lang` (value: {lang}): main language of the transcript. If set to 'auto', detect language automatically.

Behavior rules:
0. Steps to follow carefully: Syntax correction -> Chunking -> Title generation -> Output formatting. (this rule is VERY IMPORTANT FOR YOU TO FOLLOW)
1. Correct only non-substantive syntax errors: punctuation, obvious typos, unmatched quotes, spacing and the most serious ones are mismatch/wrong/unrelated/nonsense words between speech and text generated by ASR system. Do NOT paraphrase, summarize, condense, or change facts or technical expressions.
2. Each chunk must be coherent and contextually relevant. Aim for semantic unity (a chunk should cover a single topic/idea or tightly related set of sentences). However, don't break the transcript too short (< 3 sentences). (this rule is VERY IMPORTANT)
3. Maximum chunk size is `max_token` tokens. Use the specified tokenizer to count tokens.
4. Title each chunk with a short topic name (in the transcript's main language. It also mustn't contain some characters that are not allowed for filenames like '/') followed by start and end times as integers, using the exact format:
   <title> | <start_time> | <end_time>
5. Output formatting: produce consecutive chunks separated by a line of ten equals signs "==========" and each chunk must follow exactly this template:

<title N> | <start_time N> | <end_time N>
++++++++++
<chunk_text N>

==========
(repeat for all chunks)

6. Do not use any markdown styling (no bold, italic, underline). Convert math expression to LaTeX using inline ($...$) or display ($$...$$) (this rule is the MOST IMPORTANT)
7. Do not add any commentary, metadata, or notes outside the specified format.

Now process the document below using these rules:
{document}
"""


@lru_cache(maxsize=1)
def _get_client() -> genai.Client:
    if not config.GOOGLE_API_KEY:
        raise RuntimeError("GOOGLE_API_KEY not set")
    logger.info("Initializing Google Gemini client")
    client = genai.Client(api_key=config.GOOGLE_API_KEY)
    return client


_semaphore = None
limit = 5


def _get_semaphore():
    """Lazy-init a semaphore to cap outbound concurrency and avoid rate limits."""
    global _semaphore, limit
    if _semaphore is None:
        _semaphore = asyncio.Semaphore(limit)
    return _semaphore


def parse_response_into_chunks(
    response_text: str, text_type: Literal["transcript", "document"] = "transcript"
) -> list[tuple[str, str]]:

    chunk_separator = "\n=========="
    chunks = response_text.strip().split(chunk_separator)
    title_template = (
        "{title} || {start_time} || {end_time}"
        if text_type == "transcript"
        else "{title}"
    )
    parsed_chunks = []

    for chunk in chunks:
        try:
            if text_type == "transcript":
                title_line, chunk_text = chunk.split("\n++++++++++\n", 1)
                title_parts = title_line.split(" | ")
                if len(title_parts) != 3:
                    logger.warning(f"Unexpected title format: {title_line}")
                    continue
                title, start_time, end_time = title_parts
                title = title_template.format(
                    title=title.strip(),
                    start_time=start_time.strip(),
                    end_time=end_time.strip(),
                )

            else:  # document
                title_line, chunk_text = chunk.split("\n++++++++++\n", 1)
                title = title_template.format(title=title_line.strip())

            parsed_chunks.append((title, chunk_text.strip()))

        except Exception as e:
            logger.error(f"Error parsing chunk: {e}")
            continue
    return parsed_chunks


async def chunk_text(
    raw_text: str,
    text_type: Literal["transcript", "document"] = "transcript",
    save_outputs: bool = True,
    output_dir: str = config.CHUNKED_TRANSCRIPT_STORAGE_PATH,
    max_tokens: int = config.MAX_TOKENS,
) -> list[tuple[str, str]]:
    """Return a list of list of tuples: (title, chunk_text) with len = len(filepaths)"""

    client = _get_client()

    try:
        if text_type == "transcript":
            prompt = transcript_chunking_template.format(
                transcript=raw_text, max_token=max_tokens, lang="vi"
            )
        elif text_type == "document":
            prompt = document_chunking_template.format(
                document=raw_text, max_token=max_tokens, lang="vi"
            )
        else:
            raise ValueError(f"Invalid text_type: {text_type}")

        logger.info(f"Sending chunking request for type **{text_type}**...")

        model_config = types.GenerateContentConfig(
            system_instruction="You are an expert in chunking texts into smaller, coherent chunks for information retrieval systems. And you must follow the rules in the prompt strictly.",
            thinking_config=types.ThinkingConfig(thinking_budget=-1),
        )
        sem = _get_semaphore()
        async with sem:
            response = await asyncio.to_thread(
                client.models.generate_content,
                model=MODEL_ID,
                contents=prompt,
                config=model_config,
            )

        chunks = parse_response_into_chunks(
            response_text=response.text, text_type=text_type
        )

        if save_outputs:
            os.makedirs(output_dir, exist_ok=True)
            for title, chunk_text in chunks:
                chunk_path = os.path.join(output_dir, f"{title}.txt")
                with open(chunk_path, "w", encoding="utf-8") as cf:
                    cf.write(chunk_text)

        return chunks

    except Exception as e:
        logger.error(f"Error chunking transcript: {e}")
        return []
